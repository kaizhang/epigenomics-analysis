[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A guide to the single-cell epigenomics analysis",
    "section": "",
    "text": "Preface\nThis book is used to complement the documentation of the SnapATAC2 Python/Rust package."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code."
  },
  {
    "objectID": "anndata.html#introduction",
    "href": "anndata.html#introduction",
    "title": "2  AnnData – Annotated Data",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nAnnData is both a data structure and an on-disk file specification that facilitates the sharing of labeled data matrices.\nThe Python anndata package supports both in-memory and on-disk representation of AnnData object. For detailed descriptions about the AnnData format, please read anndata’s documentation.\nDespite being an excellent package, the anndata package falls shall of its support for the on-disk representation or backed mode of AnnData object. When opened in the backed mode, the in-memory snapshot and on-disk data of AnnData are not in sync with each other, causing inconsistent and unexpected behaviors. For example in the backed mode, anndata only supports updates to the X slot in the AnnData object, which means any changes to other slots like obs will not be written to disk. This make the backed mode very cumbersome to use and often lead to unexpected outcomes. Also, as it still reads all other componenets except X into memory, it uses a lot of memory for large datasets.\nTo address these limitations, SnapATAC2 implements its own out-of-core AnnData object with the following key features:\n\nAnnData is fully backed by the underlying hdf5 file. Any operations on the AnnData object will be reflected on the hdf5 file.\nAll elements are lazily loaded. No matter how large is the file, opening it consume almost zero memory. Matrix data can be accessed and processed by chunks, which keeps the memory usage to the minimum.\nIn-memory cache can be turned on to speed up the repetitive access of elements.\nFeaturing an AnnDataSet object to lazily concatenate multiple AnnData objects."
  },
  {
    "objectID": "anndata.html#a-tutorial-on-using-backed-anndata-objects",
    "href": "anndata.html#a-tutorial-on-using-backed-anndata-objects",
    "title": "2  AnnData – Annotated Data",
    "section": "2.2 A tutorial on using backed AnnData objects",
    "text": "2.2 A tutorial on using backed AnnData objects\nIn this section, we will learn the basics about SnapATAC2’s AnnData implementation.\n\n2.2.1 Reading/opening a h5ad file.\nSnapATAC2 can open h5ad files in either in-memory mode or backed mode. By default, snapatac2.read open a h5ad file in backed mode.\n\nimport snapatac2 as snap\nadata = snap.read(snap.datasets.pbmc5k(type='h5ad'))\nadata\n\nAnnData object with n_obs x n_vars = 4363 x 6176550 backed at '/home/kaizhang/.cache/snapatac2/atac_pbmc_5k.h5ad'\n    obs: 'tsse', 'n_fragment', 'frac_dup', 'frac_mito', 'doublet_score', 'is_doublet', 'leiden'\n    var: 'selected'\n    uns: 'scrublet_sim_doublet_score', 'scrublet_threshold', 'spectral_eigenvalue', 'reference_sequences', 'peaks'\n    obsm: 'X_spectral', 'X_umap', 'insertion'\n    obsp: 'distances'\n\n\nYou can turn the backed mode off using backed=False, which will use the Python anndata package to read the file and create an in-memory AnnData object.\n\nimport snapatac2 as snap\nadata = snap.read(snap.datasets.pbmc5k(type='h5ad'), backed=False)\nadata\n\nUpdating file 'atac_pbmc_5k.h5ad' from 'http://renlab.sdsc.edu/kai/public_datasets/single_cell_atac/atac_pbmc_5k.h5ad' to '/home/kaizhang/.cache/snapatac2'.\n\n\nAnnData object with n_obs × n_vars = 4363 × 6176550\n    obs: 'tsse', 'n_fragment', 'frac_dup', 'frac_mito', 'doublet_score', 'is_doublet', 'leiden'\n    var: 'selected'\n    uns: 'peaks', 'reference_sequences', 'scrublet_sim_doublet_score', 'scrublet_threshold', 'spectral_eigenvalue'\n    obsm: 'X_spectral', 'X_umap', 'insertion'\n    obsp: 'distances'\n\n\n\n\n2.2.2 Closing a backed AnnData object\nThe backed AnnData object in SnapATAC2 does not need to be saved as it is always in sync with the data on disk. However, if you have opened the h5ad file in write mode, it is important to remember to close the file using the AnnData.close method. Otherwise, the underlying hdf5 file might be corrupted.\n\nadata = snap.read(snap.datasets.pbmc5k(type='h5ad'))\nadata.close()\nadata\n\nClosed AnnData object\n\n\n\n\n2.2.3 Creating a backed AnnData object\nYou can use the AnnData constructor to create a new AnnData object.\n\nadata = snap.AnnData(filename='adata.h5ad')\nadata\n\nAnnData object with n_obs x n_vars = 0 x 0 backed at 'adata.h5ad'\n\n\nYou can then modify slots in the AnnData object.\n\nimport numpy as np\nadata.X = np.ones((3, 4))\nadata.obs_names = [\"1\", \"2\", \"3\"]\nadata.var_names = [\"a\", \"b\", \"c\", \"d\"]\nadata.obsm['matrix'] = np.ones((3, 10))\nadata.varm['another_matrix'] = np.ones((4, 10))\nadata\n\nAnnData object with n_obs x n_vars = 3 x 4 backed at 'adata.h5ad'\n    obsm: 'matrix'\n    varm: 'another_matrix'\n\n\nThe matrices are now saved on the backing hdf5 file and will be cleared from the memory.\n\n\n2.2.4 Accessing elements in a backed AnnData object\nSlots in backed AnnData object, e.g., AnnData.X, AnnData.obs, store references to the actual data. Accessing those slots does not automatically perform dereferencing or load the data into memory. Instead, a lazy element will be returned, as demonstrated in the example below:\n\nadata.X\n\n3 x 4 Array(Float(U8)) element, cache_enabled: no, cached: no\n\n\nHowever, asscessing the slots by keys will automatically read the data:\n\nadata.obsm['matrix']\n\narray([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n\n\nTo retreive the lazy element from obsm, you can use:\n\nadata.obsm.el('matrix')\n\n3 x 10 Array(Float(U8)) element, cache_enabled: no, cached: no\n\n\nSeveral useful methods haven been implemented for lazy elements. For example, you can use the slicing operator to read the full data or a part of the data:\n\nadata.X[:]\n\narray([[1., 1., 1., 1.],\n       [1., 1., 1., 1.],\n       [1., 1., 1., 1.]])\n\n\n\nadata.X[:2, :2]\n\narray([[1., 1.],\n       [1., 1.]])\n\n\nYou can also iterate over the chunks of the matrix using the chunked method:\n\nfor chunk, fr, to in adata.obsm.el('matrix').chunked(chunk_size=2):\n    print(\"from row {} to {}: {}\".format(fr, to - 1, chunk))\n\nfrom row 0 to 1: [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\nfrom row 2 to 2: [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n\n\nBy default AnnData will read from the disk each time you request the data. This will incur a lot of IO overheads if you do this repetitively.\n\n%%time\nfor _ in range(1000):\n    adata.obsm['matrix']\n\nCPU times: user 18.4 ms, sys: 279 µs, total: 18.7 ms\nWall time: 18.6 ms\n\n\nOne solution to this is to turn on the cache for the element you want to repetitively read from.\n\n%%time\nadata.obsm.el('matrix').enable_cache()\nfor _ in range(1000):\n    adata.obsm['matrix']\n\nCPU times: user 801 µs, sys: 0 ns, total: 801 µs\nWall time: 809 µs\n\n\nThe data will be cached the first time you request it and the subsequent calls will make use of the cached data.\n\n\n2.2.5 Subsetting the AnnData\nThe backed AnnData object does not have “views”. Instead, you need to use the AnnData.subset method to create a new AnnData object.\n\nadata_subset = adata.subset([0, 1], [0, 1], out=\"subset.h5ad\")\nadata_subset\n\nAnnData object with n_obs x n_vars = 2 x 2 backed at 'subset.h5ad'\n    obsm: 'matrix'\n    varm: 'another_matrix'\n\n\nYou could also do this inplace without the out parameter:\n\nadata_subset.subset([0])\nadata_subset\n\nAnnData object with n_obs x n_vars = 1 x 2 backed at 'subset.h5ad'\n    obsm: 'matrix'\n    varm: 'another_matrix'\n\n\n\n\n2.2.6 Convert to in-memory representation\nFinally, you can convert a backed AnnData to anndata’s in-memory AnnData object using:\n\nadata.to_memory()\n\nAnnData object with n_obs × n_vars = 3 × 4\n    obsm: 'matrix'\n    varm: 'another_matrix'"
  },
  {
    "objectID": "anndata.html#combining-multiple-anndata-objects-into-a-anndataset-object",
    "href": "anndata.html#combining-multiple-anndata-objects-into-a-anndataset-object",
    "title": "2  AnnData – Annotated Data",
    "section": "2.3 Combining multiple AnnData objects into a AnnDataSet object",
    "text": "2.3 Combining multiple AnnData objects into a AnnDataSet object\nOftentimes you want to combine and deal with multiple h5ad files simultaniously. In this section you will learn how to do this efficiently.\nFirst, let us create a bunch of AnnData objects.\n\ndef create_anndata(index: int):\n    adata = snap.AnnData(\n        X=np.ones((4, 7))*index,\n        filename=str(index) + \".h5ad\",\n    )\n    adata.var_names = [str(i) for i in range(7)]\n    adata.obs_names = [str(i) for i in range(4)]\n    adata.obsm['matrix'] = np.random.rand(4,50)\n    return adata\nlist_of_anndata = [(str(i), create_anndata(i)) for i in range(10)]\n\nWe can then use the AnnDataSet constructor to horizontally concatenate all AnnData objects.\n\ndataset = snap.AnnDataSet(\n    adatas=list_of_anndata,\n    filename=\"dataset.h5ads\",\n    add_key=\"id\",\n)\ndataset\n\nAnnDataSet object with n_obs x n_vars = 40 x 7 backed at 'dataset.h5ads'\ncontains 10 AnnData objects with keys: '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'\n    obs: 'id'\n    uns: 'AnnDataSet'\n\n\nAnnDataSet is just a special form of AnnData objects. It inherits most of the methods from AnnData. It carries its own annotations, such as obs, var, obsm, etc. Besides, it grants you the access to component AnnData objects as well, as shown in the example below:\n\ndataset.adatas.obsm['matrix']\n\narray([[0.645444  , 0.51504421, 0.72883674, ..., 0.07300066, 0.98447187,\n        0.70236389],\n       [0.07390566, 0.29147274, 0.7096648 , ..., 0.40711815, 0.08359172,\n        0.29094699],\n       [0.34940684, 0.74439852, 0.13199907, ..., 0.39263826, 0.42370225,\n        0.34984159],\n       ...,\n       [0.92020714, 0.74375838, 0.59506475, ..., 0.04782973, 0.41858974,\n        0.44948326],\n       [0.41591666, 0.63638591, 0.04625217, ..., 0.34052614, 0.77180976,\n        0.98088965],\n       [0.36762871, 0.81782607, 0.89817895, ..., 0.22523039, 0.01643454,\n        0.5769035 ]])\n\n\n\n2.3.1 Subsetting an AnnDataSet object\nAnnDataSet can be subsetted in a way similar to AnnData objects. But there is one caveat: subsetting an AnnDataSet will not rearrange the rows across component AnnData objects.\n\n\n2.3.2 Converting AnnDataSet to AnnData\nAn in-memory AnnData can be made from AnnDataSet using:\n\ndataset.to_adata()\n\nAnnData object with n_obs × n_vars = 40 × 7\n    obs: 'id'\n    uns: 'AnnDataSet'"
  },
  {
    "objectID": "file_format.html#fragment-interval-format",
    "href": "file_format.html#fragment-interval-format",
    "title": "3  Input data format",
    "section": "3.1 Fragment interval format",
    "text": "3.1 Fragment interval format\nFragments are created by two separate transposition events, which create the two ends of the observed fragment. Each unique fragment may generate multiple duplicate reads. These duplicate reads are collapsed into a single fragment record. A fragment record must contain exactly five fields:\n\nReference genome chromosome of fragment.\nAdjusted start position of fragment on chromosome.\nAdjusted end position of fragment on chromosome. The end position is exclusive, so represents the position immediately following the fragment interval.\nThe cell barcode of this fragment.\nThe total number of read pairs associated with this fragment. This includes the read pair marked unique and all duplicate read pairs.\n\nDuring data import, a fragment record is converted to two insertions corresponding to the start and end position of the fragment interval."
  },
  {
    "objectID": "file_format.html#insertion-format",
    "href": "file_format.html#insertion-format",
    "title": "3  Input data format",
    "section": "3.2 Insertion format",
    "text": "3.2 Insertion format\nInsertion records are used to represent single-end reads in experiments that sequence only one end of the fragments, e.g., Paired-Tag experiments. While fragment records are created by two transposition events, insertion records correspond to a single transposition event.\nEach insertion record must contain six fields:\n\nReference genome chromosome.\nAdjusted start position on chromosome.\nAdjusted end position on chromosome. The end position is exclusive.\nThe cell barcode of this fragment.\nThe total number of reads associated with this insertion.\nThe strandness of the read.\n\nDuring data import, the 5’ end of an insertion record is converted to one insertion count.\nNote: in both cases, the fifth column (duplication count) is not used during reads counting. In other words, we count duplicated reads only once. If you want to count the same record multiple times, you need to duplicate them in the input file."
  },
  {
    "objectID": "dim_reduct.html#spectral-embedding",
    "href": "dim_reduct.html#spectral-embedding",
    "title": "4  Dimension reduction",
    "section": "4.1 Spectral embedding",
    "text": "4.1 Spectral embedding\nStart with \\(n \\times p\\) cell by feature count matrix \\(M\\), we first compute the \\(n \\times n\\) pairwise similarity matrix \\(S\\) such that \\(S_{ij} = \\delta(M_{i*}, M_{j*})\\), where \\(\\delta: \\mathbb{R}^p \\times \\mathbb{R}^p \\rightarrow \\mathbb{R}\\) is the function defines the similarity between any two cells. Typical choices of \\(\\delta\\) include the jaccard index and the cosine similarity.\nWe then compute the normalized graph Laplacian \\(L = I - D^{-1/2} S D^{-1/2}\\), where \\(I\\) is the identity matrix and \\(D\\) is a diagonal matrix such that \\(D_{ii} = \\sum_k S_{ik}\\).\nThe eigenvectors correspond to the k+1-smallest eigenvalues of \\(L\\) are selected as the lower dimensional embedding."
  },
  {
    "objectID": "dim_reduct.html#nyström-method",
    "href": "dim_reduct.html#nyström-method",
    "title": "4  Dimension reduction",
    "section": "4.2 Nyström method",
    "text": "4.2 Nyström method\nFor samples with large numbers of cells, computing the full similarity matrix is slow and requires a large amount of memory. To address this limitation and increase the scalability of spectral embedding, we used the Nystrom method to perform a low-rank approximation of the full similarity matrix.\nWe will be focusing on generating an approximation \\(\\tilde{S}\\) of \\(S\\) based on a sample of \\(l ≪ n\\) of its columns.\nSuppose \\(S = \\begin{bmatrix} A & B \\\\ B^T & C \\end{bmatrix}\\) and columns \\(\\begin{bmatrix} A \\\\ B^T \\end{bmatrix}\\) are our samples. We first perform eigendecomposition on \\(A = U \\Lambda U^T\\). The nystrom method approximates the eigenvectors of matrix \\(S\\) by \\(\\tilde{U} = \\begin{bmatrix} U \\\\ B^T U \\Lambda^{-1} \\end{bmatrix}\\).\nWe can then compute \\(\\tilde{S}\\):\n\\[\n\\begin{aligned}\n\\tilde{S} &= \\tilde{U} \\Lambda \\tilde{U}^T \\\\\n          &= \\begin{bmatrix} U \\\\ B^T U \\Lambda^{-1} \\end{bmatrix}\n             \\Lambda\n             \\begin{bmatrix} U^T & \\Lambda^{-1}U^TB \\end{bmatrix} \\\\\n          &= \\begin{bmatrix}\n               U \\Lambda U^T & U \\Lambda \\Lambda^{-1} U^T B \\\\\n               B^T U \\Lambda^{-1} \\Lambda U^T & B^T U \\Lambda^{-1} \\Lambda \\Lambda^{-1} U^T B\n             \\end{bmatrix} \\\\\n          &= \\begin{bmatrix} A & B \\\\ B^T & B^T U \\Lambda^{-1} U^T B \\end{bmatrix}\n\\end{aligned}\n\\]\nIn practice, \\(\\tilde{S}\\) does not need to be computed. Instead, it is used implicitly to estimate the degree normalization vector:\n\\[\n\\tilde{d} = \\tilde{S}\\mathbf{1} = \\begin{bmatrix}A\\mathbf{1} + B\\mathbf{1} \\\\ B^T \\mathbf{1} + B^T A^{-1} B\\mathbf{1}\n\\end{bmatrix}\n\\]\n\n\n\n\nFang, Rongxin, Sebastian Preissl, Yang Li, Xiaomeng Hou, Jacinta Lucero, Xinxin Wang, Amir Motamedi, et al. 2021. “Comprehensive analysis of single cell ATAC-seq data with SnapATAC.” Nature Communications 12 (1): 1337. https://doi.org/10.1038/s41467-021-21583-9."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Fang, Rongxin, Sebastian Preissl, Yang Li, Xiaomeng Hou, Jacinta Lucero,\nXinxin Wang, Amir Motamedi, et al. 2021. “Comprehensive analysis of single cell ATAC-seq data with\nSnapATAC.” Nature Communications 12 (1): 1337. https://doi.org/10.1038/s41467-021-21583-9."
  }
]